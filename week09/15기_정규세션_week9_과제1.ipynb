{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "15기_정규세션_week9_과제1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytaWF9tLFQ0T"
      },
      "source": [
        "# Week 9 과제 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btozx60gSkCX"
      },
      "source": [
        "**잎 사진을 통한 질병 분류**\n",
        "\n",
        "*   데이터: 21개의 클래스로 구분된 약 20000장의 이미지\n",
        "><img src=\"https://drive.google.com/uc?id=1YQkxnNy61Gyi3Gp6ylCKeS72BVruJXr_\" width=\"700\" height=\"500\"> \n",
        "*   데이터 전처리\n",
        "    *   전체 데이터를 train,validation,test로 분할해주세요\n",
        "    *   저는 6:2:2로 분할했는데, 비율은 바꾸셔도 무방합니다.\n",
        "   \n",
        "    \n",
        "*   학습 진행 방향\n",
        "    *   Baseline 모델(pre-trained model 사용X) 구축\n",
        "    *   Pre-trained 모델 사용\n",
        "    *   Baseline과 ResNet50 모델의 성능을 비교해주세요 ~!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSXsUPLeJYmh",
        "outputId": "bba0f6e9-bd32-4c0b-a5f1-01ebf2a59fb2"
      },
      "source": [
        "# gdrive에 mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# 경로 설정\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IchWiK1ZFQ0X"
      },
      "source": [
        "## 0. 데이터 분할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jEtmXkaFQ0Z"
      },
      "source": [
        "* 데이터 분할을 위한 디렉토리 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noaRskGmVFBP"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "DIR = '/content/gdrive/MyDrive/Colab Notebooks/tobigs15/'\n",
        "original_dataset_dir = DIR+'tobigs_week9_plant_leaf/'   \n",
        "classes_list = os.listdir(original_dataset_dir) \n",
        " \n",
        "base_dir = DIR+'tobigs_week9_splitted/' "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fG-dk2dFQ0Z"
      },
      "source": [
        "os.mkdir(base_dir)\n",
        " \n",
        "train_dir = os.path.join(base_dir, 'train') \n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list:     \n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQyurQ6FQ0a"
      },
      "source": [
        "* 데이터 분할과 클래스별 데이터 수 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1nrkw0nFQ0b",
        "outputId": "aab8476d-a03d-4650-c144-4985dabe786b"
      },
      "source": [
        "import math\n",
        " \n",
        "for cls in classes_list:\n",
        "    path = os.path.join(original_dataset_dir, cls)\n",
        "    fnames = os.listdir(path)\n",
        " \n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    validation_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "    \n",
        "    train_fnames = fnames[:train_size]\n",
        "    print(\"Train size(\",cls,\"): \", len(train_fnames))\n",
        "    for fname in train_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "    print(\"Validation size(\",cls,\"): \", len(validation_fnames))\n",
        "    for fname in validation_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    test_fnames = fnames[(train_size+validation_size):(validation_size + train_size +test_size)]\n",
        "\n",
        "    print(\"Test size(\",cls,\"): \", len(test_fnames))\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size( Potato___Early_blight ):  600\n",
            "Validation size( Potato___Early_blight ):  200\n",
            "Test size( Potato___Early_blight ):  200\n",
            "Train size( Apple___Cedar_apple_rust ):  165\n",
            "Validation size( Apple___Cedar_apple_rust ):  55\n",
            "Test size( Apple___Cedar_apple_rust ):  55\n",
            "Train size( Grape___Black_rot ):  708\n",
            "Validation size( Grape___Black_rot ):  236\n",
            "Test size( Grape___Black_rot ):  236\n",
            "Train size( Grape___healthy ):  253\n",
            "Validation size( Grape___healthy ):  84\n",
            "Test size( Grape___healthy ):  84\n",
            "Train size( Strawberry___healthy ):  273\n",
            "Validation size( Strawberry___healthy ):  91\n",
            "Test size( Strawberry___healthy ):  91\n",
            "Train size( Cherry___Powdery_mildew ):  631\n",
            "Validation size( Cherry___Powdery_mildew ):  210\n",
            "Test size( Cherry___Powdery_mildew ):  210\n",
            "Train size( Potato___Late_blight ):  600\n",
            "Validation size( Potato___Late_blight ):  200\n",
            "Test size( Potato___Late_blight ):  200\n",
            "Train size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  645\n",
            "Validation size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
            "Test size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
            "Train size( Pepper,_bell___healthy ):  894\n",
            "Validation size( Pepper,_bell___healthy ):  298\n",
            "Test size( Pepper,_bell___healthy ):  298\n",
            "Train size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  307\n",
            "Validation size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
            "Test size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
            "Train size( Pepper,_bell___Bacterial_spot ):  598\n",
            "Validation size( Pepper,_bell___Bacterial_spot ):  199\n",
            "Test size( Pepper,_bell___Bacterial_spot ):  199\n",
            "Train size( Apple___Black_rot ):  372\n",
            "Validation size( Apple___Black_rot ):  124\n",
            "Test size( Apple___Black_rot ):  124\n",
            "Train size( Apple___healthy ):  987\n",
            "Validation size( Apple___healthy ):  329\n",
            "Test size( Apple___healthy ):  329\n",
            "Train size( Cherry___healthy ):  512\n",
            "Validation size( Cherry___healthy ):  170\n",
            "Test size( Cherry___healthy ):  170\n",
            "Train size( Corn___healthy ):  700\n",
            "Validation size( Corn___healthy ):  233\n",
            "Test size( Corn___healthy ):  233\n",
            "Train size( Corn___Northern_Leaf_Blight ):  591\n",
            "Validation size( Corn___Northern_Leaf_Blight ):  197\n",
            "Test size( Corn___Northern_Leaf_Blight ):  197\n",
            "Train size( Grape___Esca_(Black_Measles) ):  829\n",
            "Validation size( Grape___Esca_(Black_Measles) ):  276\n",
            "Test size( Grape___Esca_(Black_Measles) ):  276\n",
            "Train size( Corn___Common_rust ):  715\n",
            "Validation size( Corn___Common_rust ):  238\n",
            "Test size( Corn___Common_rust ):  238\n",
            "Train size( Apple___Apple_scab ):  378\n",
            "Validation size( Apple___Apple_scab ):  126\n",
            "Test size( Apple___Apple_scab ):  126\n",
            "Train size( Strawberry___Leaf_scorch ):  670\n",
            "Validation size( Strawberry___Leaf_scorch ):  223\n",
            "Test size( Strawberry___Leaf_scorch ):  223\n",
            "Train size( Potato___healthy ):  91\n",
            "Validation size( Potato___healthy ):  30\n",
            "Test size( Potato___healthy ):  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZDnksn0FQ0c"
      },
      "source": [
        "## 1. 베이스라인 모델을 구축해 주세요\n",
        "* Pre-Trained Model을 사용하지 않고 직접 모델을 구축해 주세요 !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm7kPbfsFQ0d"
      },
      "source": [
        "import torch\n",
        "import os\n",
        " \n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "BATCH_SIZE = 256 \n",
        "EPOCH = 30 "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl_j5EzoFQ0d"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder \n",
        " \n",
        "transform_base = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()]) \n",
        "train_dataset = ImageFolder(root=base_dir+'train/', transform=transform_base) \n",
        "val_dataset = ImageFolder(root=base_dir+'val/', transform=transform_base)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djFeShktFQ0d",
        "outputId": "445c9d62-f61f-4641-90fb-4b808a2fed2a"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDEhzqZRFQ0e"
      },
      "source": [
        "* 베이스라인 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJE-jG9UFQ0e"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        " \n",
        "class Net(nn.Module): \n",
        "  \n",
        "    def __init__(self): \n",
        "    \n",
        "        super(Net, self).__init__()\n",
        "        conv1 = nn.Conv2d(in_channels=3, out_channels = 64, kernel_size = (5,5), stride = 1, padding = 2) # (64+2*2-5)/1 + 1 = 64\n",
        "        relu = nn.ReLU()\n",
        "        maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        conv2 = nn.Conv2d(in_channels=64, out_channels = 64, kernel_size = (3,3), stride = 1, padding = 2)  \n",
        "        conv3 = nn.Conv2d(in_channels=64, out_channels = 32, kernel_size = (3,3), stride = 2, padding = 1)     \n",
        "        # conv4 = nn.Conv2d(in_channels=256, out_channels = 128, kernel_size = (3,3), stride = 1)   \n",
        "        fc1 = nn.Linear(32*4*4, 128)\n",
        "        fc2 = nn.Linear(128, 21)\n",
        "        \n",
        "        self.convnet = nn.Sequential(\n",
        "            conv1, relu, maxpool2, # 32\n",
        "            conv2, relu, maxpool2, # 17\n",
        "            conv3, relu, maxpool2 # 4\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            fc1, relu,\n",
        "            fc2\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):  \n",
        "\n",
        "        output = self.convnet(x)\n",
        "        output = output.view(x.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return F.log_softmax(output, dim=1)  \n",
        "\n",
        "model_base = Net().to(DEVICE)  \n",
        "optimizer = optim.Adam(model_base.parameters(), lr=0.005) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LowbXUGKFQ0e"
      },
      "source": [
        "* 모델 학습을 위한 함수\n",
        "* 모델 학습, 평가를 위한 가이드라인 코드입니다. 꼭 이 코드를 사용하지는 않으셔도 됩니다 !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GL1mNqzFQ0f"
      },
      "source": [
        "def train(model, train_loader, optimizer, criterion, scheduler):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE) \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data) \n",
        "        loss = criterion(output, target)      #Cross Entropy Loss 사용했습니다\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler:\n",
        "            scheduler.step()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqvOveaxFQ0f"
      },
      "source": [
        "* 모델 평가를 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncm8J6v4FQ0f"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0 \n",
        "    correct = 0   \n",
        "    \n",
        "    with torch.no_grad(): \n",
        "        for data, target in test_loader:  \n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)  \n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item() \n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() \n",
        "   \n",
        "    test_loss /= len(test_loader.dataset) \n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset) \n",
        "    return test_loss, test_accuracy  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us-wigmEFQ0g"
      },
      "source": [
        "* 모델 학습을 실행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_hvkStsFQ0g"
      },
      "source": [
        "import time\n",
        "import copy\n",
        " \n",
        "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30, criterion = nn.CrossEntropyLoss(), scheduler = None):\n",
        "    best_acc = 0.0  \n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
        " \n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        since = time.time()  \n",
        "        train(model, train_loader, optimizer, criterion, scheduler)\n",
        "        train_loss, train_acc = evaluate(model, train_loader)\n",
        "        val_loss, val_acc = evaluate(model, train_loader)\n",
        "        \n",
        "        if val_acc > best_acc: \n",
        "            best_acc = val_acc \n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        time_elapsed = time.time() - since \n",
        "        print('-------------- epoch {} ----------------'.format(epoch))\n",
        "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
        "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
        "\n",
        "    model.load_state_dict(best_model_wts)  \n",
        "    return model\n",
        "\t"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1GrcoZglzfr",
        "outputId": "506b9f88-1cad-4db9-fcf8-76436288f4d6"
      },
      "source": [
        "base = train_baseline(model_base, train_loader, val_loader, optimizer)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 2.1222, Accuracy: 32.34%\n",
            "val Loss: 2.1222, Accuracy: 32.34%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 1.3907, Accuracy: 53.70%\n",
            "val Loss: 1.3907, Accuracy: 53.70%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 0.9552, Accuracy: 67.73%\n",
            "val Loss: 0.9552, Accuracy: 67.73%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 0.7298, Accuracy: 75.94%\n",
            "val Loss: 0.7298, Accuracy: 75.94%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.5816, Accuracy: 80.13%\n",
            "val Loss: 0.5816, Accuracy: 80.13%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 6 ----------------\n",
            "train Loss: 0.5221, Accuracy: 81.69%\n",
            "val Loss: 0.5221, Accuracy: 81.69%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 7 ----------------\n",
            "train Loss: 0.4782, Accuracy: 83.30%\n",
            "val Loss: 0.4782, Accuracy: 83.30%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 8 ----------------\n",
            "train Loss: 0.3264, Accuracy: 89.20%\n",
            "val Loss: 0.3264, Accuracy: 89.20%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 9 ----------------\n",
            "train Loss: 0.3252, Accuracy: 88.83%\n",
            "val Loss: 0.3252, Accuracy: 88.83%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 10 ----------------\n",
            "train Loss: 0.4203, Accuracy: 85.35%\n",
            "val Loss: 0.4203, Accuracy: 85.35%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 11 ----------------\n",
            "train Loss: 0.2343, Accuracy: 91.70%\n",
            "val Loss: 0.2343, Accuracy: 91.70%\n",
            "Completed in 1m 7s\n",
            "-------------- epoch 12 ----------------\n",
            "train Loss: 0.2502, Accuracy: 91.12%\n",
            "val Loss: 0.2502, Accuracy: 91.12%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 13 ----------------\n",
            "train Loss: 0.2545, Accuracy: 90.36%\n",
            "val Loss: 0.2545, Accuracy: 90.36%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 14 ----------------\n",
            "train Loss: 0.1986, Accuracy: 92.69%\n",
            "val Loss: 0.1986, Accuracy: 92.69%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 15 ----------------\n",
            "train Loss: 0.2808, Accuracy: 90.12%\n",
            "val Loss: 0.2808, Accuracy: 90.12%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 16 ----------------\n",
            "train Loss: 0.1844, Accuracy: 93.06%\n",
            "val Loss: 0.1844, Accuracy: 93.06%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 17 ----------------\n",
            "train Loss: 0.1309, Accuracy: 95.49%\n",
            "val Loss: 0.1309, Accuracy: 95.49%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 18 ----------------\n",
            "train Loss: 0.1896, Accuracy: 92.86%\n",
            "val Loss: 0.1896, Accuracy: 92.86%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 19 ----------------\n",
            "train Loss: 0.1765, Accuracy: 93.57%\n",
            "val Loss: 0.1765, Accuracy: 93.57%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 20 ----------------\n",
            "train Loss: 0.1405, Accuracy: 95.07%\n",
            "val Loss: 0.1405, Accuracy: 95.07%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 21 ----------------\n",
            "train Loss: 0.1205, Accuracy: 95.47%\n",
            "val Loss: 0.1205, Accuracy: 95.47%\n",
            "Completed in 1m 6s\n",
            "-------------- epoch 22 ----------------\n",
            "train Loss: 0.1318, Accuracy: 95.19%\n",
            "val Loss: 0.1318, Accuracy: 95.19%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 23 ----------------\n",
            "train Loss: 0.2017, Accuracy: 92.46%\n",
            "val Loss: 0.2017, Accuracy: 92.46%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 24 ----------------\n",
            "train Loss: 0.1934, Accuracy: 93.03%\n",
            "val Loss: 0.1934, Accuracy: 93.03%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 25 ----------------\n",
            "train Loss: 0.1216, Accuracy: 95.46%\n",
            "val Loss: 0.1216, Accuracy: 95.46%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 26 ----------------\n",
            "train Loss: 0.1558, Accuracy: 94.16%\n",
            "val Loss: 0.1558, Accuracy: 94.16%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 27 ----------------\n",
            "train Loss: 0.0941, Accuracy: 96.53%\n",
            "val Loss: 0.0941, Accuracy: 96.53%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 28 ----------------\n",
            "train Loss: 0.0667, Accuracy: 97.51%\n",
            "val Loss: 0.0667, Accuracy: 97.51%\n",
            "Completed in 1m 5s\n",
            "-------------- epoch 29 ----------------\n",
            "train Loss: 0.0775, Accuracy: 97.21%\n",
            "val Loss: 0.0775, Accuracy: 97.21%\n",
            "Completed in 1m 4s\n",
            "-------------- epoch 30 ----------------\n",
            "train Loss: 0.0590, Accuracy: 97.93%\n",
            "val Loss: 0.0590, Accuracy: 97.93%\n",
            "Completed in 1m 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBma4mCciyAz"
      },
      "source": [
        "torch.save(base,base_dir + 'baseline.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mV-CQwZFQ0h"
      },
      "source": [
        "## 2. Transfer Learning 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDoeutltFQ0h"
      },
      "source": [
        "* Transfer Learning을 위한 준비\n",
        "* Transfer Learning이 익숙하지 않으신 분들은 PyTorch에서 제공하는 https://9bow.github.io/PyTorch-tutorials-kr-0.3.1/beginner/transfer_learning_tutorial.html 을 참고하세요 :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so4pOWIqFQ0i"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([transforms.Resize([64,64]), \n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        # transforms.CenterCrop(52),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),\n",
        "    \n",
        "    'val': transforms.Compose([transforms.Resize([64,64]),  \n",
        "        'validation 데이터는 Test 데이터와 동일한 조건이어야 합니다.'\n",
        "        'validation에 맞는 전처리를 수행해 주세요',\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.CenterCrop(52),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Tbg8YzFQ0j"
      },
      "source": [
        "### Pre-Trained Model 불러오기\n",
        "- 저는 ResNet50을 사용했는데, 코랩 기준으로 다른 ResNet계열이나 DenseNet 정도까지는 큰 무리 없이 훈련할 수 있습니다. Unfreeze layer 수가 적으면 다른 모델도 사용할 수 있을 것입니다.\n",
        "- 한 가지 모델을 선택해서 Transfer Learning을 해 주세요 !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3CwSwMWFQ0j"
      },
      "source": [
        "from torchvision import models\n",
        " \n",
        "resnet = models.resnet50(pretrained=True)  \n",
        "num_ftrs = resnet.fc.in_features   \n",
        "resnet.fc = nn.Linear(num_ftrs, 21)\n",
        "resnet = resnet.to(DEVICE)\n",
        " \n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.01)\n",
        " \n",
        "from torch.optim import lr_scheduler  #scheduler는 사용하지 않으셔도 됩니다 (선택사항)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)  #7에폭마다 learning rate를 조절하는 역할을 합니다"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQoS058cFQ0k"
      },
      "source": [
        "* Pre-Trained Model의 일부 Layer Freeze하기 (resnet 기준입니다 !!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXzgnWxkFQ0k",
        "outputId": "06e17fb5-cd45-4f55-f41d-420e331a0a17"
      },
      "source": [
        "ct = 0 \n",
        "for child in resnet.children():  \n",
        "    ct+= 1  \n",
        "    print(\"#{}\".format(ct), child)\n",
        "    if ct < 6: \n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "#2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "#3 ReLU(inplace=True)\n",
            "#4 MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "#5 Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "#6 Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "#7 Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (5): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "#8 Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "#9 AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "#10 Linear(in_features=2048, out_features=21, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWdXTYBaFQ0l"
      },
      "source": [
        "* Fine Tuning을 진행해주세요 ~!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q80q_1MYRdZk"
      },
      "source": [
        "train_dataset = ImageFolder(root=base_dir+'train/', transform=data_transforms['train']) \n",
        "val_dataset = ImageFolder(root=base_dir+'val/', transform=data_transforms['val'])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKNH31LuRdi2",
        "outputId": "1d627dce-6793-4b1f-c9b9-dd89fb01faab"
      },
      "source": [
        "resnet_trained = train_baseline(resnet, train_loader, val_loader, optimizer_ft, criterion = nn.CrossEntropyLoss(), num_epochs=15)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 3.0335, Accuracy: 34.75%\n",
            "val Loss: 2.9867, Accuracy: 34.39%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 0.7827, Accuracy: 75.98%\n",
            "val Loss: 0.7883, Accuracy: 75.64%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 0.5041, Accuracy: 82.86%\n",
            "val Loss: 0.6633, Accuracy: 82.81%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 0.2453, Accuracy: 90.99%\n",
            "val Loss: 0.2463, Accuracy: 91.11%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.2795, Accuracy: 91.05%\n",
            "val Loss: 0.2853, Accuracy: 90.47%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 6 ----------------\n",
            "train Loss: 0.2462, Accuracy: 91.71%\n",
            "val Loss: 0.2385, Accuracy: 92.14%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 7 ----------------\n",
            "train Loss: 0.0803, Accuracy: 97.02%\n",
            "val Loss: 0.0767, Accuracy: 97.23%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 8 ----------------\n",
            "train Loss: 0.0891, Accuracy: 96.97%\n",
            "val Loss: 0.0875, Accuracy: 97.06%\n",
            "Completed in 1m 56s\n",
            "-------------- epoch 9 ----------------\n",
            "train Loss: 0.0904, Accuracy: 96.77%\n",
            "val Loss: 0.0880, Accuracy: 96.77%\n",
            "Completed in 1m 56s\n",
            "-------------- epoch 10 ----------------\n",
            "train Loss: 0.0841, Accuracy: 97.01%\n",
            "val Loss: 0.0827, Accuracy: 97.07%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 11 ----------------\n",
            "train Loss: 0.0644, Accuracy: 97.86%\n",
            "val Loss: 0.0656, Accuracy: 97.86%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 12 ----------------\n",
            "train Loss: 0.0314, Accuracy: 98.92%\n",
            "val Loss: 0.0315, Accuracy: 98.92%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 13 ----------------\n",
            "train Loss: 0.0697, Accuracy: 97.68%\n",
            "val Loss: 0.0720, Accuracy: 97.57%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 14 ----------------\n",
            "train Loss: 0.0559, Accuracy: 97.88%\n",
            "val Loss: 0.0595, Accuracy: 97.87%\n",
            "Completed in 1m 57s\n",
            "-------------- epoch 15 ----------------\n",
            "train Loss: 0.0828, Accuracy: 97.20%\n",
            "val Loss: 0.0748, Accuracy: 97.49%\n",
            "Completed in 1m 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ9FK199Rdyd"
      },
      "source": [
        "torch.save(resnet_trained, base_dir + 'resnet50_.pt')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZXgc0G_FQ0m"
      },
      "source": [
        "## 모델 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q42vR5_FQ0n"
      },
      "source": [
        "* 모델 평가를 위해서는 평가 데이터 또한 전처리를 해주어야 합니다.\n",
        "* validation 데이터와 동일하게 전처리를 해 주세요 ~!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr5LkMzMRxVk"
      },
      "source": [
        "* 베이스라인 모델 평가를 위한 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EfLf3GOFQ0n",
        "outputId": "69e6cbd1-f0ff-4805-89ef-324c1c6d538d"
      },
      "source": [
        "transform_base = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()]) \n",
        "test_base = ImageFolder(root=base_dir+'test/',transform=transform_base)  \n",
        "test_loader_base = torch.utils.data.DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KISksPR3FQ0n"
      },
      "source": [
        "* Transfer Learning모델 평가를 위한 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BTGBjTzFQ0n",
        "outputId": "6af834d9-8b05-4b6c-8f26-4a886bd79c7a"
      },
      "source": [
        "transform_resNet = transforms.Compose([\n",
        "        transforms.Resize([64,64]),  \n",
        "        # \"채워주세요\"\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "    ])\n",
        "    \n",
        "test_resNet = ImageFolder(root=base_dir+'test/', transform=transform_resNet) \n",
        "test_loader_resNet = torch.utils.data.DataLoader(test_resNet,batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J4OJRfCSrrM"
      },
      "source": [
        "### 성능 평가하기\n",
        "* 저는 여기서 accuracy만을 평가했지만, 분류 모델이기에 다양한 방법의 평가가 가능합니다.\n",
        "* Confusion Matrix를 이용한 비교도 가능하고, 한 작물에 해당하는 클래스가 여러개인 다중 분류에서 F1-score를 계산하는것도 의미가 있을 것입니다. \n",
        "* 다양한 시도를 하시는 분께 가산점 드리겠습니다 :):)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGFNIsYfFQ0o"
      },
      "source": [
        "* 베이스라인 모델 성능 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsJCTvboFQ0o",
        "outputId": "0ed595cf-e177-44ab-a011-51109caba9f8"
      },
      "source": [
        "baseline=torch.load(base_dir+'baseline.pt') \n",
        "baseline.eval()  \n",
        "test_loss, test_accuracy = evaluate(baseline, test_loader_base)\n",
        "\n",
        "print('test acc:  ', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc:   91.86652763295099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guqq1ZHiFQ0o"
      },
      "source": [
        "* Transfer Learning 모델 성능 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxfqIEkeFQ0o",
        "outputId": "43ec9e93-a4ae-4363-b282-cea40cb8bd7b"
      },
      "source": [
        "resnet50=torch.load(base_dir+'resnet50_.pt') \n",
        "# resnet50 = resnet_trained\n",
        "resnet50.eval()  \n",
        "test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n",
        "\n",
        "print('test acc:  ', test_accuracy)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc:   97.21063607924921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8wZSpB6R7c1"
      },
      "source": [
        "* 두 모델의 성능을 비교 평가하는 설명을 작성해주세요 ~!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_La4fXyfK0l"
      },
      "source": [
        "base로는 CNN layer 3개와 FC layer 2개로 이뤄진 모델을 구상하였다. 그 결과, test accuracy는 91.87%로 나왔다. \n",
        "Transfer Learning은 ResNet 50모델에서 앞에서 5개의 레이어를 freeze한 후 fine tuning을 진행하였다. 그 결과, base model보다 훨씬 빠르게 학습이 진행되었으며 최종적으로 test accuracy는 97.2%로 나왔다."
      ]
    }
  ]
}